{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План створення контенту для заняття\n",
    "\n",
    "#### **Тема 4. Заняття 4. Оцінка точності та налаштування гіперпараметрів моделі**\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Методи оцінки точності моделі**\n",
    "\n",
    "#### **Теоретичний матеріал**\n",
    "1. Основні поняття:\n",
    "   - Тренувальна, валідаційна, та тестова вибірки.\n",
    "   - Метричні показники оцінки точності: \n",
    "     - `Accuracy`, `Precision`, `Recall`, `F1-score`.\n",
    "     - Для регресійних моделей: `Mean Absolute Error (MAE)`, `Mean Squared Error (MSE)`, `R²`.\n",
    "   - Перехресна перевірка (Cross-validation).\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Основні поняття: Оцінка точності моделі**\n",
    "\n",
    "#### **1. Тренувальна, валідаційна та тестова вибірки**\n",
    "- **Тренувальна вибірка** — це частина даних, яка використовується для навчання моделі. Модель аналізує ці дані, щоб знайти закономірності між вхідними значеннями (факторами) та вихідними (результатами). Зазвичай ця вибірка складає 60–80% від загального набору даних.\n",
    "  \n",
    "- **Валідаційна вибірка** використовується для перевірки продуктивності моделі під час її налаштування. Наприклад, якщо ви змінюєте параметри моделі, валідаційна вибірка допоможе оцінити, чи покращується її робота. Вона допомагає уникнути перенавчання, коли модель запам’ятовує лише тренувальні дані, але не може працювати з новими.\n",
    "\n",
    "- **Тестова вибірка** використовується на завершальному етапі для оцінки того, наскільки добре модель може передбачати результати на нових даних, які вона не бачила під час навчання. Це своєрідний фінальний іспит для моделі.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Метричні показники оцінки точності**\n",
    "\n",
    "##### **Для класифікаційних моделей:**\n",
    "- **Точність (Accuracy):**  \n",
    "  Показує, яку частку передбачень модель зробила правильно, порівнюючи їх із реальними значеннями. Це базова метрика, яка добре працює, якщо всі класи мають однакову важливість.\n",
    "\n",
    "- **Прецизійність (Precision):**  \n",
    "  Показує, наскільки передбачення моделі позитивного класу є правильними. Ця метрика корисна, коли важливо мінімізувати хибнопозитивні передбачення, наприклад, у випадках діагностики хвороб.\n",
    "\n",
    "- **Повнота (Recall):**  \n",
    "  Відображає, наскільки модель добре знаходить всі реальні позитивні випадки. Це важливо, коли критичніше зменшити кількість хибнонегативних передбачень, наприклад, при виявленні шахрайства.\n",
    "\n",
    "- **F1-міра:**  \n",
    "  Є балансом між прецизійністю та повнотою. Використовується, коли важливо враховувати обидві метрики, особливо якщо дані є незбалансованими (наприклад, один клас зустрічається значно частіше за інший).\n",
    "\n",
    "##### **Для регресійних моделей:**\n",
    "- **Середня абсолютна помилка (MAE):**  \n",
    "  Це середній розмір відхилення передбачень від реальних значень. Ця метрика легко інтерпретується, оскільки вимірюється в тих самих одиницях, що й дані.\n",
    "\n",
    "- **Середня квадратична помилка (MSE):**  \n",
    "  Показує середній розмір відхилення, але більше \"штрафує\" великі помилки. Це робить її корисною, якщо великі відхилення мають важливе значення.\n",
    "\n",
    "- **Коефіцієнт детермінації (R²):**  \n",
    "  Оцінює, наскільки добре модель пояснює зміни в даних. Значення, близьке до 1, означає, що модель дуже добре відображає дані.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Перехресна перевірка (Cross-validation)**\n",
    "Це метод, який дозволяє оцінити якість моделі, використовуючи весь набір даних більш ефективно. Замість того, щоб фіксувати одну частину для навчання, а іншу для тестування, дані розділяються на кілька груп (підмножин). Модель навчається на частині цих підмножин, а перевіряється на решті. Цей процес повторюється кілька разів, що дає середній показник точності.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Практична користь цих понять**\n",
    "Ці методи та метрики дозволяють визначити:\n",
    "- Наскільки добре модель працює на різних етапах.\n",
    "- Як уникнути проблеми перенавчання.\n",
    "- Як підібрати параметри для досягнення найкращих результатів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Приклади використання:\n",
    "   - Розділення даних на навчальні та тестові за допомогою `train_test_split`.\n",
    "   - Використання функцій з бібліотеки `sklearn` для оцінки точності.\n",
    "\n",
    "#### **Код для прикладу**\n",
    "**Приклад на основі датасету з Kaggle: \"Iris Dataset\"**\n",
    "\n",
    "```python\n",
    "# Імпорт бібліотек\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Завантаження даних\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Підготовка даних\n",
    "X = data.drop('species', axis=1)\n",
    "y = data['species']\n",
    "\n",
    "# Розділення на тренувальні та тестові вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Побудова моделі\n",
    "model = RandomForestClassifier(random_state=42, n_estimators = 50)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Оцінка точності\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Перехресна перевірка\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Cross-Validation Accuracy:\", cv_scores.mean())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **2. Методи налаштування гіперпараметрів моделі**\n",
    "\n",
    "#### **Теоретичний матеріал**\n",
    "1. **Методи налаштування:**\n",
    "   - Ручний підбір (Manual Search).\n",
    "   - Сітковий пошук (Grid Search).\n",
    "   - Випадковий пошук (Random Search).\n",
    "   - Адаптивні методи (Bayesian Optimization, Hyperopt, Optuna).\n",
    "\n",
    "2. Приклади гіперпараметрів:\n",
    "   - `n_estimators`, `max_depth`, `learning_rate` для `RandomForest` або `XGBoost`.\n",
    "\n",
    "3. Бібліотеки для автоматизації пошуку:\n",
    "   - `GridSearchCV`, `RandomizedSearchCV` з `sklearn`.\n",
    "\n",
    "#### **Код для прикладу**\n",
    "**Налаштування гіперпараметрів для `RandomForest`**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Задаємо сітку параметрів\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Налаштування гіперпараметрів\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Виведення найкращих параметрів\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Оцінка точності з оптимальними параметрами\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "print(\"Optimized Accuracy:\", accuracy_score(y_test, y_pred_optimized))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Практичне завдання**\n",
    "1. **Обрати простий набір даних з Kaggle (наприклад, \"Iris Dataset\").**\n",
    "2. **Виконати наступні кроки:**\n",
    "   - Розділити дані на тренувальну та тестову вибірки.\n",
    "   - Побудувати базову модель та оцінити її точність за допомогою метрик (`accuracy`, `F1-score`).\n",
    "   - Провести перехресну перевірку (Cross-validation).\n",
    "   - Використати `GridSearchCV` або `RandomizedSearchCV` для налаштування гіперпараметрів моделі.\n",
    "   - Порівняти результати до та після налаштування гіперпараметрів.\n",
    "\n",
    "3. **Оформити результати у вигляді звіту (включити графіки точності та таблиці параметрів).**\n",
    "\n",
    "---\n",
    "\n",
    "### **Вихідний файл**\n",
    "Готовий `.ipynb` файл створено для завантаження та використання під час заняття.\n",
    "\n",
    "\n",
    "Результати аналізу:\n",
    "\n",
    "1. **Точність базової моделі:**\n",
    "   - Точність на тестовій вибірці: **1.0 (100%)**.\n",
    "   - Перехресна перевірка: **1.0 (100%)**.\n",
    "   - Звіт по метриках: точність, повнота і F1-міра також становлять 1.0.\n",
    "\n",
    "2. **Налаштовані параметри:**\n",
    "   - `max_depth`: `None` (без обмежень).\n",
    "   - `min_samples_split`: `2` (мінімум 2 зразки для поділу вузла).\n",
    "   - `n_estimators`: `10` (кількість дерев у моделі).\n",
    "\n",
    "3. **Точність моделі після налаштування гіперпараметрів:**\n",
    "   - Оптимізована точність: **1.0 (100%)**.\n",
    "\n",
    "Ці результати були досягнуті на невеликій локальній вибірці для демонстрації. В реальних умовах рекомендується використовувати більший набір даних для точнішої оцінки. Готовий `.ipynb` файл з усіма кроками буде збережений для подальшого використання.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
